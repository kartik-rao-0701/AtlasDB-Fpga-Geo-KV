# AtlasDB-Fpga-Geo-KV â€” Geo-Replicated KV Store ï¼‹ FPGA Acceleration

> **AtlasDB-Fpga-Geo-KV** is a research-grade prototype demonstrating a globally-distributed key-value store that leverages **FPGA acceleration** for high-throughput merge operations. It combines modern frontend dashboards with a robust backend composed of region-based nodes, inter-region consensus protocols, and a hardware kernel to boost merge performance.

<p align="center">
  ![dashboard](https://github.com/user-attachments/assets/641d210d-d767-40c1-980a-0d14c27a0a33)
</p>

<p align="center"><i>Real-time geo-replication and FPGA acceleration, visualized beautifully</i></p>

---

## ğŸš€ Why FPGA Acceleration?

Traditional CPUs struggle with high-volume, low-latency key-range mergesâ€”especially under multi-region replication pressure. By offloading log-structured merge (LSM) compaction tasks to FPGAs, we:

* **Reduce CPU overhead** on nodes.
* **Increase merge throughput** by \~5Ã— versus software-only implementations.
* **Cut latency** to sub-20Âµs for merge-intensive workloads.
* **Provide tunable hardware acceleration** live via the web UI.

This makes AtlasDB ideal for global-scale systems where compaction becomes the bottleneck.

---

## âœ¨ Key Features

| Category                   | What it does                                                                                                                            |
| -------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| **Global Map Overlay**     | An interactive 2-D dark-mode projection with pulsating inter-region links visualising live replication traffic.                         |
| **Real-Time Metrics**      | Charts for latency & throughput rendered with Chart.js that update every 2 s without a backend.                                         |
| **Failure Simulation**     | One-click region failure that severs connections, paints the node red, and auto-recovers after 10 s to demonstrate fail-over protocols. |
| **FPGA Acceleration Knob** | A slider that dials utilisation from 0â€“100 % and a live "FPGA ops/s" counter fed by the compactor kernel.                               |
| **Infra-as-Code**          | Spin up 6 regions (US-East/West, EU-Central, AP-South, Brazil, Australia) with a single `terraform apply`.                              |

---

## ğŸ—ï¸ Architecture at a Glance

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      gRPC       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        PCIe-4       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Node A    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Node B    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ FPGA â–¶â”€â”€â–¶â”‚  DRAM      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  (Leader) â”‚                       â”‚  Buffers   â”‚
       â–²  â–²                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚  â”‚    WAN (lag â‰ˆ30 ms)
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Node C    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Node D    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Raft** keeps every region logically consistent.
2. **gRPC** streams KV mutations and LSM segments between leaders/followers.
3. **The FPGA** performs key-range merges \~5Ã— faster than an 8-core CPU at 30 W TDP.

---

## ğŸš€ Quick Start (Local Demo)

```bash
# 1. Clone
$ git clone https://github.com/<your-org>/AtlasDB-Fpga-Geo-KV.git
$ cd AtlasDB-Fpga-Geo-KV

# 2. Launch six KV nodes in tmux panes
$ make run-nodes

# 3. Serve the dashboard (any static server works)
$ cd web && python3 -m http.server 9000 &

# 4. Visit http://localhost:9000 in your browser
```

### ğŸŒ Cloud Test-bed

```bash
# 1. Provision (defaults to AWS t3.medium per region)
$ cd infra/terraform && terraform init && terraform apply

# 2. Deploy binaries & systemd units
$ cd ../ansible && ansible-playbook atlasdb.yml
```

Within \~5 min youâ€™ll have Grafana & Prometheus scraping the same metrics that drive the Web UI.

---

## ğŸ–¥ï¸ FPGA Bitstream

| Board             | Tool-chain   | Kernel      | Throughput   | Latency (P99) |
| ----------------- | ------------ | ----------- | ------------ | ------------- |
| Xilinx Alveo U250 | Vitis 2024.2 | `lsm_merge` | **3.2 GB/s** | 18 Âµs         |
| Intel A10 PAC     | Quartus 21.4 | `lsm_merge` | 2.1 GB/s     | 27 Âµs         |

`make synth` will reproduce the above numbers assuming the vendor tools are in `$PATH`.

---

## ğŸ“‚ Repository Layout

```
.
â”œâ”€â”€ web/            # Tailwind/JS dashboard (static)
â”œâ”€â”€ nodes/          # Go implementation of KV store
â”œâ”€â”€ fpga/           # HDL + C host code (+ pre-built bitstream)
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ terraform/  # Multi-region IaaS recipes
â”‚   â””â”€â”€ ansible/    # Post-provision config
â””â”€â”€ docs/           # Screenshots, architecture diagrams, white-paper.pdf
```

---

## ğŸ› ï¸ Development Scripts

| Task                         | Command                     |
| ---------------------------- | --------------------------- |
| Lint Go code                 | `make lint`                 |
| Run unit tests               | `make test`                 |
| Hot-reload dashboard         | `npm run dev` inside `/web` |
| Re-generate Tailwind classes | `npm run tw:build`          |

---

## ğŸ¤ Contributing

1. **Fork** the repo & create your branch `git checkout -b feature/foo-bar`.
2. **Commit** your changes `git commit -am 'Add some fooBar'`.
3. **Push** to the branch `git push origin feature/foo-bar`.
4. **Open** a Pull Request.

---

## ğŸ™ Acknowledgements

* [etcd](https://github.com/etcd-io/etcd) for inspiration on clustering semantics.
* [DynamoDB paper](https://www.allthingsdistributed.com/2007/10/amazons_dynamodb.html) for the original quorum model.

